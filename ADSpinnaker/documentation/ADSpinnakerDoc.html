<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>FLIR Spinnaker areaDetector driver</title>
  <meta content="text/html; charset=ISO-8859-1" http-equiv="Content-Type" />
</head>
<body>
  <div style="text-align: center">
    <h1>
      FLIR Spinnaker areaDetector driver</h1>
    <h2>
      March 26, 2018</h2>
    <h2>
      Mark Rivers</h2>
    <h2>
      University of Chicago</h2>
  </div>
  <h2>
    Table of Contents</h2>
  <ul>
    <li><a href="#Introduction">Introduction</a></li>
    <li><a href="#Firmware">Camera firmware</a></li>
    <li><a href="#VideoModes">Video modes</a></li>
    <li><a href="#Format7Modes">Format7 modes</a></li>
    <li><a href="#PixelFormats">Pixel formats</a></li>
    <li><a href="#FrameRates">Frame rates</a></li>
    <li><a href="#Properties">Properties</a></li>
    <li><a href="#StandardParameters">Standard driver parameters</a></li>
    <li><a href="#DriverParameters">Point Grey specific driver parameters</a></li>
    <li><a href="#Configuration">Configuration</a></li>
    <li><a href="#MEDM_screens">MEDM screens</a></li>
  </ul>
  <h2 id="Introduction" style="text-align: left">
    Introduction</h2>
  <p>
    This is an <a href="http://www.aps.anl.gov/epics/">EPICS</a> <a href="areaDetector.html">
      areaDetector</a> driver for cameras from <a href="http://www.flir.com">FLIR</a> (formerly Point Grey).
    It uses their new Spinnaker SDK, while the ADPointGrey driver uses their older FlyCap2 SDK.
    It should work with most GigE, 10GigE, and USB 3.0 cameras. It has been tested on
    GigE (BlackFlyS), and USB 3.0 (Grasshopper3) cameras. 
  </p>
  <p>
    The driver should work on both Windows and Linux.  However, so far it has only been tested on Windows. 
    The problem is that the Spinnaker SDK is only supported on Ubuntu 16.  There are 2 contraints that prevent it
    from running on older Linux versions, and on other distributions.  The  libSpinnaker.so file from their Spinnaker SDK
    was built with gcc 5.4 and requires GLIBC 2.14 and GLIBCXX 3.4.21. This means it cannot be used with gcc 4.8 on RHEL 7,
    for example.  Furthermore the Spinnaker libraries depend on these shareable libraries: libswscale-ffmpeg.so.3, 
    libavcodec-ffmpeg.so.56, libavutil-ffmpeg.so.54, and libavformat-ffmpeg.so.56.  These libraries come from an ffmpeg
    package that appears to only be available for Ubuntu, and not for Red Hat/Centos distributions.  Building ffmpeg from source
    does not even work because the .so library names and the symbols inside those libraries do not match the ones that the Spinnaker SDK
    was built with.  This is unfortunate, and I have asked FLIR to consider distributing a version of the SDK that will build on RHEL 7.
  </p>
  <p>
    This driver inherits from <a href="areaDetectorDoc.html#ADDriver">ADDriver</a>.
    It implements many of the parameters in <a href="areaDetectorDoxygenHTML/asyn_n_d_array_driver_8h.html">
      asynNDArrayDriver.h</a> and in <a href="areaDetectorDoxygenHTML/_a_d_driver_8h.html">
        ADArrayDriver.h</a>. It also implements a number of parameters that are specific
    to the Spinnaker cameras. The <a href="areaDetectorDoxygenHTML/classspinnaker.html">
      spinnaker class documentation</a> describes this class in detail.</p>
  <h2 id="Firmware" style="text-align: left">
    Camera firmware</h2>
  <p>
    FLIR frequently updates the available firmware for each camera to add features
    and fix bugs. However, they are not very good about putting the link to the latest
    firmware on their Web site. At present one must e-mail the support team (mv-support@flir.com)
    and ask them if newer firmware is available for a particular camera, and if so to
    provide access to it. They normally do this by sending a link to a Dropbox folder.</p>
  <h2 id="Properties" style="text-align: left">
    Properties</h2>
  <p>
    The Spinnaker SDK supports cameras that use the <a href="http://www.emva.org/standards-technology/genicam/">GenICam</a> interface.  
    This includes <a href="https://en.wikipedia.org/wiki/GigE_Vision">GigE Vision</a> and 
    <a href="https://www.visiononline.org/vision-standards-details.cfm?id=167&type=5">USB3 Vision</a> cameras.
    GenICam cameras have an XML file in the camera that describes the complete list of properties that the camera supports.
    These properties can be accessed in a generic manner.  This means that libraries that support GenICam are quite simple
    to use, since all properties are accessed in a generic way.  It supports introspection, so that software can determine
    which properties are supported, and what the allowed ranges and choices for a specific property are.  The ADSpinnaker
    driver is only 60% of the size of the old ADPointGrey driver because of the simplicity of the SDK.  The choices
    for menu-type properties are built at run-time from the values supported by the camera.  For some properties these choices
    can change dynamically when some other property is changed.  EPICS Channel Access does not support callbacks when enum choices
    change.  This means that GUI clients cannot update the choices on an open screen when the driver changes them.  For this reason
    enum records that can change their choices at run-time are displayed on a related display (ADSpinnakerMore) that must be closed
    and re-opened to see the new choices.  The valid range of numeric properties can similarly change dynamically at run-time
    based on changes in other properties.  These changes will be immediately reflected the DRVL, DRVH, LOPR, and HOPR fields of 
    the records.  However, EPICS Channel Access does not support callbacks when graphics display limits change, 
    so EPICS GUI clients do not update slider widget limits when HOPR and LOPR change.  For this reason numeric
    records that can change their choices at run-time are also displayed on ADSpinnakerMore that must be closed
    and re-opened to have the slider limits update.  
  </p>
  <h2 id="StandardParameters" style="text-align: left">
    Standard areaDetector parameters</h2>
  <p>
    The following table describes how the Point Grey driver implements some of the standard
    driver parameters.
  </p>
  <table border="1" cellpadding="2" cellspacing="2" style="text-align: left">
    <tbody>
      <tr>
        <td align="center" colspan="3">
          <b>Implementation of Parameters in asynNDArrayDriver.h and ADDriver.h, and EPICS Record
            Definitions in ADBase.template and NDFile.template</b> </td>
      </tr>
      <tr>
        <th>
          Parameter index variable </th>
        <th>
          EPICS record name </th>
        <th>
          Description </th>
      </tr>
      <tr>
        <td>
          ADTriggerMode </td>
        <td>
          $(P)$(R)TriggerMode </td>
        <td>
          The choices for the Point Grey are:
          <ul>
            <li>"Internal". The timing is internal to the detector.</li>
            <li>"Ext. standard". Each external trigger pulse starts the next image. The exposure
              time is controlled internally by the AcquireTime record.</li>
            <li>"Bulb". The rising edge of the external trigger signal starts the next image.
              The detector continues to acquire while the external signal is high, and then reads
              out the detector on the falling edge of the external trigger signal.</li>
            <li>"Skip frames". One external trigger pulse starts an image and then the next N
              external trigger signals are ignored. The SkipFrames record defines N.</li>
            <li>"Multi-exposure". One external trigger pulse starts an image and then the next
              N-1 external trigger signals cause an additional exposure into the same image. The
              image is read out after trigger N. The NumExposures record defines N.</li>
            <li>"Multi-exposure bulb". A combination of bulb and multi-exposure modes above. N
              exposures are accumulated into an image before it is read out. The time in the logic
              high state determines the acquire time for each exposure. The NumExposures record
              defines N.</li>
            <li>"Low-smear". Smear reduction works by increasing the speed of the vertical clock
              near the end of the integration cycle. See the Technical Reference Manual for the
              camera for more information.</li>
            <li>"Multi-shot". A single external trigger causes N images to be acquired. The NumImages
              record defines N. NumImages is limited to a maximum 255 in this mode.</li>
          </ul>
          Note that the minimum time between external trigger pulses is no more than the maximum
          value of FrameRate in the current mode, and may be less for a particular camera.
          Note also that not all cameras support all TriggerModes. The TriggerMode enum string
          choices are only those supported for the camera in use. </td>
      </tr>
      <tr>
        <td>
          ADTemperatureActual </td>
        <td>
          $(P)$(R)TemperatureActual </td>
        <td>
          The readback of the temperature. </td>
      </tr>
      <tr>
        <td>
          ADNumImages </td>
        <td>
          $(P)$(R)NumImages </td>
        <td>
          Controls the number of images to acquire. When TriggerMode=Internal this is handled
          in software. When TriggerMode=Multi-shot it is handled in the camera firmware.
        </td>
      </tr>
      <tr>
        <td>
          ADNumExposures </td>
        <td>
          $(P)$(R)NumExposures </td>
        <td>
          Controls the number of exposures per image when TriggerMode="Multi-exposure" or
          "Multi-exposure bulb". </td>
      </tr>
      <tr>
        <td>
          ADAcquireTime </td>
        <td>
          $(P)$(R)AcquireTime </td>
        <td>
          Controls the acquisition time per image. This is converted into the ShutterAbsVal
          control of the SHUTTER property. ShutterAbsVal = AcquireTime*1000., because SHUTTER
          units are ms. </td>
      </tr>
      <tr>
        <td>
          ADAcquirePeriod </td>
        <td>
          $(P)$(R)AcquirePeriod </td>
        <td>
          Controls the period between images. This is converted into the FrameRateAbsVal control
          of the FRAME_RATE property. FrameRateAbsVal = 1./AcquirePeriod. </td>
      </tr>
      <tr>
        <td>
          ADGain </td>
        <td>
          $(P)$(R)Gain </td>
        <td>
          Controls the analog gain on the camera. This is converted into the GainAbsVal control
          of the GAIN property. The units are dB. </td>
      </tr>
    </tbody>
  </table>
  <h2 id="DriverParameters">
    Point Grey specific driver parameters</h2>
  <p>
    The Point Grey driver implements the following parameters in addition to those in
    asynNDArrayDriver.h and ADDriver.h. The database file is spinnaker.template for
    all records except the property records, which are in spinnakerProperty.template.
  </p>
  <table border="1" cellpadding="2" cellspacing="2" style="text-align: left">
    <tbody>
      <tr>
        <td align="center" colspan="7">
          <b>Parameter Definitions in firewireWinDCAM.cpp and EPICS Record Definitions</b>
        </td>
      </tr>
      <tr>
        <th>
          Parameter index variable </th>
        <th>
          asyn interface </th>
        <th>
          Access </th>
        <th>
          Description </th>
        <th>
          drvInfo string </th>
        <th>
          EPICS record name </th>
        <th>
          EPICS record type </th>
      </tr>
      <tr>
        <td align="center" colspan="7">
          <b>Video mode parameters</b> </td>
      </tr>
      <tr>
        <td>
          PGVideoMode </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The video mode. All possible values are listed in the <a href="#VideoModes">Video
            modes</a> section above. The actual enum choices for this record will only include
          the video modes supported by the camera in use. </td>
        <td>
          PG_VIDEO_MODE </td>
        <td>
          $(P)$(R)VideoMode<br />
          $(P)$(R)VideoMode_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td>
          PGFormat7Mode </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The Format7 mode when the camera is in VideoMode=Format7. This is discussed in the
          <a href="#Format7Modes">Format7 modes</a> section above. The actual enum choices
          for this record will only include the Format7 modes supported by the camera in use.
        </td>
        <td>
          PG_FORMAT7_MODE </td>
        <td>
          $(P)$(R)Format7Mode<br />
          $(P)$(R)Format7Mode_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td>
          PGPixelFormat </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The pixel format when the camera is in VideoMode=Format7. This is discussed in the
          <a href="#PixelFormats">Pixel formats</a> section above. The actual enum choices
          for this record will only include the pixel formats supported by the camera in use
          for the Format7Mode currently selected. </td>
        <td>
          PG_PIXEL_FORMAT </td>
        <td>
          $(P)$(R)PixelFormat<br />
          $(P)$(R)PixelFormat_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td>
          PGConvertPixelFormat </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The driver allows converting the pixel format from the camera to another pixel format.
          The pixel formats from the camera that can be converted are:
          <ul>
            <li>Raw8</li>
            <li>Raw12</li>
            <li>Raw16</li>
            <li>Mono12</li>
          </ul>
          The pixel format that these can be converted to are:
          <ul>
            <li>None: The input pixel format is not converted.</li>
            <li>Mono8: The input pixel format is converted to Mono8.</li>
            <li>Raw16: The input pixel format is converted to Raw16. This is useful when the input
              pixel format is Raw12, since this saves network bandwidth.</li>
            <li>Mono16: The input pixel format is converted to Mono16. This is useful when the
              input pixel format is Mono12, since this saves network bandwidth. Note that the
              FlyCap2 library does not support converting Raw12 to Mono16. The difference between
              Raw16 and Mono16 is that Mono16 has the sharpness and gamma corrections applied,
              while Raw16 does not.</li>
            <li>RGB8: The input format is converted to RGB8. This is useful when the input format
              is Raw8, for a color camera. In this case Bayer color is sent on the network, reducing
              the bandwidth requirement by a factor of 3.</li>
            <li>RGB16: The input format is converted to RGB16. This is useful when the input format
              is Raw16, for a color camera. In this case Bayer color is sent on the network, reducing
              the bandwidth requirement by a factor of 3.</li>
          </ul>
        </td>
        <td>
          PG_CONVERT_PIXEL_FORMAT </td>
        <td>
          $(P)$(R)ConvertPixelFormat<br />
          $(P)$(R)ConvertPixelFormat_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td>
          PGFrameRate </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The frame rate choice when the VideoMode is not Format7. This is discussed in the
          <a href="#FrameRates">Frame rates</a> section above. The actual enum choices for
          this record will only include the frame rates supported by the camera in use for
          the VideoMode currently selected. </td>
        <td>
          PG_FRAME_RATE </td>
        <td>
          $(P)$(R)FrameRate<br />
          $(P)$(R)FrameRate_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td>
          BinningMode </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The binning mode for GigE cameras. The allowed values are camera-specific.</td>
        <td>
          PG_BINNING_MODE </td>
        <td>
          $(P)$(R)BinningMode<br />
          $(P)$(R)BinningMode_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td align="center" colspan="7">
          <b>Property parameters<br />
            These parameters apply to each of the 18 Point Grey properties discussed in the
            <a href="#Properties">Properties</a> section above.
            <br />
            The $(PROPERTY) macro in this table is the EPICS record base name listed in that
            section.<br />
            These records are defined in spinnakerProperty.template.</b> </td>
      </tr>
      <tr>
        <td>
          PGPropertyAvail </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          A flag indicating if the property is available. </td>
        <td>
          PG_PROP_AVAIL </td>
        <td>
          $(P)$(R)$(PROPERTY)Avail </td>
        <td>
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyOnOffAvail </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          A flag indicating if the property supports turning on and off. </td>
        <td>
          PG_PROP_ON_OFF_AVAIL </td>
        <td>
          $(P)$(R)$(PROPERTY)OnOffAvail </td>
        <td>
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyOnOff </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          Controls whether the property is on or off. </td>
        <td>
          PG_PROP_ON_OFF </td>
        <td>
          $(P)$(R)$(PROPERTY)OnOff
          <br />
          $(P)$(R)$(PROPERTY)OnOff_RBV </td>
        <td>
          bo
          <br />
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyOnePushAvail </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          A flag indicating if the property supports setting once (called One Push). This
          is typically used for setting things like the gain or shutter time automatically
          once.</td>
        <td>
          PG_PROP_ONE_PUSH_AVAIL </td>
        <td>
          $(P)$(R)$(PROPERTY)OnePushAvail </td>
        <td>
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyOnePush </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          Processing this record causes a one-push setting of the property. </td>
        <td>
          PG_PROP_ONE_PUSH </td>
        <td>
          $(P)$(R)$(PROPERTY)OnePush</td>
        <td>
          bo</td>
      </tr>
      <tr>
        <td>
          PGPropertyAbsAvail </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          A flag indicating if the property supports absolute (floating point) control.
        </td>
        <td>
          PG_PROP_ABS_AVAIL </td>
        <td>
          $(P)$(R)$(PROPERTY)AbsAvail </td>
        <td>
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyAutoAvail </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          A flag indicating if the property supports automatic control. </td>
        <td>
          PG_PROP_AUTO_AVAIL </td>
        <td>
          $(P)$(R)$(PROPERTY)AutoAvail </td>
        <td>
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyManAvail </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          A flag indicating if the property supports manual control. </td>
        <td>
          PG_PROP_MAN_AVAIL </td>
        <td>
          $(P)$(R)$(PROPERTY)ManAvail </td>
        <td>
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyAutoMode </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          Controls whether the property is manually controlled or automatically controlled.
        </td>
        <td>
          PG_PROP_AUTO_MODE </td>
        <td>
          $(P)$(R)$(PROPERTY)AutoMode
          <br />
          $(P)$(R)$(PROPERTY)AutoMode_RBV </td>
        <td>
          bo
          <br />
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyAbsAvail </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          A flag indicating if the property supports absolute (floating point) control.
        </td>
        <td>
          PG_PROP_ABS_AVAIL </td>
        <td>
          $(P)$(R)$(PROPERTY)AbsAvail </td>
        <td>
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyAbsMode </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          Controls whether the property is controlled in integer device units or floating
          point absolute units. </td>
        <td>
          PG_PROP_ABS_MODE </td>
        <td>
          $(P)$(R)$(PROPERTY)AbsMode
          <br />
          $(P)$(R)$(PROPERTY)AbsMode_RBV </td>
        <td>
          bo
          <br />
          bi </td>
      </tr>
      <tr>
        <td>
          PGPropertyValue </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The value of the property in integer device units. This controls the ValueA field
          of the property, which is the only integer field used for all properties except
          WHITE_BALANCE. </td>
        <td>
          PG_PROP_VAL </td>
        <td>
          $(P)$(R)$(PROPERTY)Val
          <br />
          $(P)$(R)$(PROPERTY)Val_RBV </td>
        <td>
          ao
          <br />
          ai </td>
      </tr>
      <tr>
        <td>
          PGPropertyValueB </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The value of the property in integer device units. This controls the ValueB field
          of the property, which is only used to control the Blue value of WHITE_BALANCE.
        </td>
        <td>
          PG_PROP_VAL_B </td>
        <td>
          $(P)$(R)$(PROPERTY)ValB
          <br />
          $(P)$(R)$(PROPERTY)ValB_RBV </td>
        <td>
          ao
          <br />
          ai </td>
      </tr>
      <tr>
        <td>
          PGPropertyValueMin </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The minimum value of the property in device units. This is used to control the LOPR
          and DRVL fields of the $(P)$(R)$(PROPERTY)Val record. </td>
        <td>
          PG_PROP_VAL_MIN </td>
        <td>
          $(P)$(R)$(PROPERTY)ValMin </td>
        <td>
          ai </td>
      </tr>
      <tr>
        <td>
          PGPropertyValueMax </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The maximum value of the property in device units. This is used to control the HOPR
          and DRVH fields of the $(P)$(R)$(PROPERTY)Val record. </td>
        <td>
          PG_PROP_VAL_MAX </td>
        <td>
          $(P)$(R)$(PROPERTY)ValMax </td>
        <td>
          ai </td>
      </tr>
      <tr>
        <td>
          PGPropertyValueAbs </td>
        <td>
          asynFloat64 </td>
        <td>
          r/w </td>
        <td>
          The value of the property in floating point absolute units. </td>
        <td>
          PG_PROP_VAL_ABS </td>
        <td>
          $(P)$(R)$(PROPERTY)ValAbs
          <br />
          $(P)$(R)$(PROPERTY)ValAbs_RBV </td>
        <td>
          ao
          <br />
          ai </td>
      </tr>
      <tr>
        <td>
          PGPropertyValueAbsMin </td>
        <td>
          asynFloat64 </td>
        <td>
          r/o </td>
        <td>
          The minimum value of the property in absolute units. This is used to control the
          LOPR and DRVL fields of the $(P)$(R)$(PROPERTY)ValAbs record. </td>
        <td>
          PG_PROP_VAL_ABS_MIN </td>
        <td>
          $(P)$(R)$(PROPERTY)ValAbsMin </td>
        <td>
          ai </td>
      </tr>
      <tr>
        <td>
          PGPropertyValueAbsMax </td>
        <td>
          asynFloat64 </td>
        <td>
          r/o </td>
        <td>
          The maximum value of the property in absolute units. This is used to control the
          HOPR and DRVH fields of the $(P)$(R)$(PROPERTY)ValAbs record. </td>
        <td>
          PG_PROP_VAL_ABS_MAX </td>
        <td>
          $(P)$(R)$(PROPERTY)ValAbsMax </td>
        <td>
          ai </td>
      </tr>
      <tr>
        <td align="center" colspan="7">
          <b>GigE Property parameters<br />
            These parameters apply to each of the 4 Point Grey GigE properties discussed in
            the <a href="#GigEProperties">GigE Properties</a> section above.
            <br />
            The $(PROPERTY) macro in this table is the EPICS record base name listed in that
            section.<br />
            These records are defined in spinnakerProperty.template.</b> </td>
      </tr>
      <tr>
        <td>
          PGPropertyValue </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The value of the property in integer device units. This controls the ValueA field
          of the property, which is the only integer field used for all properties except
          WHITE_BALANCE. </td>
        <td>
          PG_PROP_VAL </td>
        <td>
          $(P)$(R)$(PROPERTY)Val
          <br />
          $(P)$(R)$(PROPERTY)Val_RBV </td>
        <td>
          ao
          <br />
          ai </td>
      </tr>
      <tr>
        <td>
          PGPropertyValueMin </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The minimum value of the property in device units. This is used to control the LOPR
          and DRVL fields of the $(P)$(R)$(PROPERTY)Val record. </td>
        <td>
          PG_PROP_VAL_MIN </td>
        <td>
          $(P)$(R)$(PROPERTY)ValMin </td>
        <td>
          ai </td>
      </tr>
      <tr>
        <td>
          PGPropertyValueMax </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The maximum value of the property in device units. This is used to control the HOPR
          and DRVH fields of the $(P)$(R)$(PROPERTY)Val record. </td>
        <td>
          PG_PROP_VAL_MAX </td>
        <td>
          $(P)$(R)$(PROPERTY)ValMax </td>
        <td>
          ai </td>
      </tr>
      <tr>
        <td align="center" colspan="7">
          <b>Trigger parameters</b> </td>
      </tr>
      <tr>
        <td>
          PGTriggerSource </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The trigger source signal. Choices are "GPIO_0", GPIO_1","GPIO_2", and "GPIO_3",
          which selects one of 4 GPIO pins on the camera. However, not all choices may be
          available on a specific camera, and the enum choices will only be the trigger sources
          actually supported on the camera in use. </td>
        <td>
          PG_TRIGGER_SOURCE </td>
        <td>
          $(P)$(R)TriggerSource
          <br />
          $(P)$(R)TriggerSource_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td>
          PGTriggerPolarity </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The trigger polarity. Choices are "Low", and "High". </td>
        <td>
          PG_TRIGGER_POLARITY </td>
        <td>
          $(P)$(R)TriggerPolarity
          <br />
          $(P)$(R)TriggerPolarity_RBV </td>
        <td>
          bo
          <br />
          bi </td>
      </tr>
      <tr>
        <td>
          PGSoftwareTrigger </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          Processing this record causes the driver to issue a software trigger. </td>
        <td>
          PG_SOFTWARE_TRIGGER </td>
        <td>
          $(P)$(R)SoftwareTrigger </td>
        <td>
          bo </td>
      </tr>
      <tr>
        <td>
          PGSkipFrames </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The number of frames to skip when TriggerMode="Skip frames". </td>
        <td>
          PG_SKIP_FRAMES </td>
        <td>
          $(P)$(R)SkipFrames
          <br />
          $(P)$(R)SkipFrames_RBV </td>
        <td>
          longout
          <br />
          longin </td>
      </tr>
      <tr>
        <td align="center" colspan="7">
          <b>Strobe parameters</b> </td>
      </tr>
      <tr>
        <td>
          PGStrobeSource </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The strobe output signal. Choices are "GPIO_0", GPIO_1","GPIO_2", and "GPIO_3",
          which selects one of 4 GPIO pins on the camera. However, not all choices may be
          available on a specific camera, and the enum choices will only be the strobe sources
          actually supported on the camera in use. </td>
        <td>
          PG_STROBE_SOURCE </td>
        <td>
          $(P)$(R)StrobeSource
          <br />
          $(P)$(R)StrobeSource_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td>
          PGStrobeEnable </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          Enables the strobe output. Choices are "Disable", and "Enable". </td>
        <td>
          PG_STROBE_ENABLE </td>
        <td>
          $(P)$(R)StrobeEnable
          <br />
          $(P)$(R)StrobeEnable_RBV </td>
        <td>
          bo
          <br />
          bi </td>
      </tr>
      <tr>
        <td>
          PGStrobePolarity </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The strobe polarity. Choices are "Low", and "High". </td>
        <td>
          PG_STROBE_POLARITY </td>
        <td>
          $(P)$(R)StrobePolarity
          <br />
          $(P)$(R)StrobePolarity_RBV </td>
        <td>
          bo
          <br />
          bi </td>
      </tr>
      <tr>
        <td>
          PGStrobeDelay </td>
        <td>
          asynFloat64 </td>
        <td>
          r/w </td>
        <td>
          The delay of the strobe signal relative to the start of acquisition. </td>
        <td>
          PG_STROBE_DELAY </td>
        <td>
          $(P)$(R)StrobeDelay
          <br />
          $(P)$(R)StrobeDelay_RBV </td>
        <td>
          ao
          <br />
          ai </td>
      </tr>
      <tr>
        <td>
          PGStrobeDuration </td>
        <td>
          asynFloat64 </td>
        <td>
          r/w </td>
        <td>
          The duration of the strobe signal. If zero then the strobe output is asserted during
          the image aquisition time. </td>
        <td>
          PG_STROBE_DURATION </td>
        <td>
          $(P)$(R)StrobeDuration
          <br />
          $(P)$(R)StrobeDuration_RBV </td>
        <td>
          ao
          <br />
          ai </td>
      </tr>
      <tr>
        <td align="center" colspan="7">
          <b>Bandwidth control parameters</b> </td>
      </tr>
      <tr>
        <td>
          PGMaxPacketSize</td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The maximum packet size. This depends on the current acquisition settings for Firewire
          and USB cameras. For GigE cameras this is determined by calling DiscoverGigEPacketSize
          at startup, which should return the maximum Ethernet packet size supported between
          the camera and the IOC. However, this sometimes returns 9000 (jumbo packets) when
          jumbo packets are not in fact supported. In this case the user should manually set
          PacketSize to 1440 or image acquisition will fail.</td>
        <td>
          PG_MAX_PACKET_SIZE </td>
        <td>
          $(P)$(R)MaxPacketSize</td>
        <td>
          longin </td>
      </tr>
      <tr>
        <td>
          PGPacketSize </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The packet size to use. This is used to control the maximum bandwidth, and hence
          maximum frame rate, on Firewire and USB cameras. For GigE cameras it should be set
          to the largest packet size supported on the Ethernet connection between the camera
          and IOC. It should be set to 1440 for connections that do not support jumbo packets,
          and as large as 9000 for connections that do support jumbo packets. If PacketSize
          is set to 0 then the driver will use the current value of MaxPacketSize.</td>
        <td>
          PG_PACKET_SIZE </td>
        <td>
          $(P)$(R)PacketSize
          <br />
          $(P)$(R)PacketSize_RBV </td>
        <td>
          ao
          <br />
          ai </td>
      </tr>
      <tr>
        <td>
          PGPacketSizeActual </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The actual packet size being used.</td>
        <td>
          PG_PACKET_SIZE_ACTUAL </td>
        <td>
          $(P)$(R)PacketSizeActual</td>
        <td>
          longin </td>
      </tr>
      <tr>
        <td>
          PGPacketDelay </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The packet delay to use in microseconds. This is used to control the maximum bandwidth,
          and hence maximum frame rate, on GigE cameras. It is not used for Firewire or USB
          cameras. The default is 400 microseconds. If the number of CorruptFrames is large
          then this can be increased, for example to 1000. This will reduce the maximum frame
          rate but can significantly reduce the number of CorruptFrames.</td>
        <td>
          PG_PACKET_DELAY </td>
        <td>
          $(P)$(R)PacketDelay
          <br />
          $(P)$(R)PacketDelay_RBV </td>
        <td>
          longout
          <br />
          longin </td>
      </tr>
      <tr>
        <td>
          PGPacketDelayActual </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The actual packet delay being used.</td>
        <td>
          PG_PACKET_DELAY_ACTUAL </td>
        <td>
          $(P)$(R)PacketDelayActual</td>
        <td>
          longin </td>
      </tr>
      <tr>
        <td>
          PGBandwidth </td>
        <td>
          asynFloat64 </td>
        <td>
          r/o </td>
        <td>
          The calculated bandidth in MB/s. This is computed from the image size and the frame
          rate.</td>
        <td>
          PG_BANDWIDTH </td>
        <td>
          $(P)$(R)Bandwidth</td>
        <td>
          ai </td>
      </tr>
      <tr>
        <td align="center" colspan="7">
          <b>Timestamp parameters</b> </td>
      </tr>
      <tr>
        <td>
          PGTimeStampMode </td>
        <td>
          asynInt32 </td>
        <td>
          r/w </td>
        <td>
          The timestamp mode. Controls the value of the NDArray,.timeStamp value. Choices
          are:
          <ul>
            <li>Camera: The time from the camera is used.</li>
            <li>EPICS: The EPICS time is used</li>
            <li>Hybrid: The EPICS time when the camera started is combined with the time stamp
              from the camera.</li>
          </ul>
        </td>
        <td>
          PG_TIME_STAMP_MODE </td>
        <td>
          $(P)$(R)TimeStampMode
          <br />
          $(P)$(R)TimeStampMode_RBV </td>
        <td>
          mbbo
          <br />
          mbbi </td>
      </tr>
      <tr>
        <td align="center" colspan="7">
          <b>Camera statistics</b> </td>
      </tr>
      <tr>
        <td>
          PGCorruptFrames </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The number of corrupt frames. The Point Grey SDK resets this to 0 each time acquisition
          is started. </td>
        <td>
          PG_CORRUPT_FRAMES </td>
        <td>
          $(P)$(R)CorruptFrames_RBV </td>
        <td>
          longin </td>
      </tr>
      <tr>
        <td>
          PGDroppedFrames </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The number of dropped frames. The Point Grey SDK resets this to 0 each time acquisition
          is started. </td>
        <td>
          PG_DROPPED_FRAMES </td>
        <td>
          $(P)$(R)DroppedFrames_RBV </td>
        <td>
          longin </td>
      </tr>
      <tr>
        <td>
          PGDriverDropped </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The number of frames dropped by the driver. The Point Grey SDK resets this to 0
          each time acquisition is started. </td>
        <td>
          PG_DRIVER_DROPPED </td>
        <td>
          $(P)$(R)DriverDropped_RBV </td>
        <td>
          longin </td>
      </tr>
      <tr>
        <td>
          PGTransmitFailed </td>
        <td>
          asynInt32 </td>
        <td>
          r/o </td>
        <td>
          The number of time transmission failed. The Point Grey SDK resets this to 0 each
          time acquisition is started. </td>
        <td>
          PG_TRANSMIT_FAILED </td>
        <td>
          $(P)$(R)TransmitFailed_RBV </td>
        <td>
          longin </td>
      </tr>
    </tbody>
  </table>
  <h2 id="Configuration">
    Configuration</h2>
  <p>
    The ADSpinnaker driver is created with the spinnakerConfig command, either from C/C++
    or from the EPICS IOC shell.</p>
  <pre>spinnakerConfig(const char *portName, const char* cameraId, int traceMask, int memoryChannel,
              int maxBuffers, size_t maxMemory, 
              int priority, int stackSize)
  </pre>
  <p>
    The cameraId parameter can either be an index of the camera in the list of available
    cameras (e.g. 0 if there is only a single Point Grey camera available) or the serial
    number of the camera to use. For additional details on the meaning of the parameters
    to this function refer to the detailed documentation on the spinnakerConfig
    function in the <a href="areaDetectorDoxygenHTML/point_grey_8cpp.html">spinnaker.cpp
      documentation</a> and in the documentation for the constructor for the <a href="areaDetectorDoxygenHTML/classpoint_grey.html">
        spinnaker class</a>.
  </p>
  <p>
    The traceMask can be set to a value &gt; 1 to enable asynTrace debugging during
    initialization, before the value can be set from the IOC shell or via the asynRecord.
    Set this to 0x21 to enable ASYN_TRACE_WARNING, which will trace all calls to the
    Point Grey FlyCap2 library.</p>
  <p>
    The memoryChannel can be set to a value &gt; 0 to load the initial camera parameters
    from non-volatile memory in the camera. Setting memoryChannel to N loads from memoryChannel
    N-1, i.e. 1 loads memory channel 0. There is currently a problem with Linux and
    for BlackFly GigE cameras. If the IOC is run a second time after it has been used
    to acquire any images the driver loses communication with the camera. The problem
    appears to be that there is a corrupt setting in the camera, which causes it to
    malfunction the next time the program is run. Setting memoryChannel 1 will work
    around this problem by replacing the settings in the camera with a default set.
    Since the EPICS IOC sets nearly all the camera settings to save/restore values at
    startup anyway, this is not a serious limitation.</p>
  <p>
    There an example IOC boot directory and startup script (<a href="point_grey_st_cmd.html">iocBoot/iocSpinnaker/st.cmd)</a>
    provided with areaDetector.
  </p>
  <h2 id="MEDM_screens" style="text-align: left">
    MEDM screens</h2>
  <p>
    The following show the MEDM screens that are used to control the Point Grey cameras.</p>
  <p>
    <code>spinnaker.adl</code> is the main screen used to control Point Grey cameras.
  </p>
  <div style="text-align: center">
    <h3 style="text-align: center">
      spinnaker.adl</h3>
    <img alt="ADSpinnaker.png" src="ADSpinnaker.png" /></div>
  <p>
    <code>spinnakerProperties.adl</code> is the screen used to control the properties
    of Point Grey cameras. Note that some of these properties, such as Shutter, FrameRate,
    and Gain can also be controlled by standard areaDetector records, like AcquireTime,
    AcquirePeriod, and Gain. The widgets on the medm screen are hidden if the corresponding
    feature is not available.
  </p>
  <div style="text-align: center">
    <h3 style="text-align: center">
      spinnakerProperties.adl for a BlackFly GigE color camera in RGB mode</h3>
    <img alt="spinnakerProperties_BlackFly.png" src="spinnakerProperties_BlackFly.png" />
    <h3 style="text-align: center">
      spinnakerProperties.adl for a Grasshopper3 monochrome camera</h3>
    <img alt="spinnakerProperties_Grasshopper3.png" src="spinnakerProperties_Grasshopper3.png" /></div>
  <p>
    <code>spinnakerFrameRate.adl</code> is the screen used to control the frame rate
    in standard video modes. This is a separate screen because the valid enum strings
    for the Framerate record can change when the standard video mode is changed. When
    that is changed it is necessary to close this screen and re-open it in order for
    the new menus to be displayed. This is a limitation of the EPICS Channel Access
    which does not send monitor events for changes in enum fields. Note that the readback
    of the FrameRate on the main spinnaker.adl screen can also be incorrect, so it may
    be necessary to close and re-open that main screen as well.
  </p>
  <div style="text-align: center">
    <h3 style="text-align: center">
      spinnakerFrameRate.adl</h3>
    <img alt="spinnakerFrameRate.png" src="spinnakerFrameRate.png" /></div>
  <p>
    <code>spinnakerPixelFormat.adl</code> is the screen used to control the pixel format
    in Format7 mode. This is a separate screen because the valid enum strings for the
    PixelFormat can change when the Format7 mode is changed. When that is changed it
    is necessary to close this screen and re-open it in order for the new menus to be
    displayed. This is a limitation of the EPICS Channel Access which does not send
    monitor events for changes in enum fields. Note that the readback of the PixelFormat
    on the main spinnaker.adl screen can also be incorrect, so it may be necessary to
    close and re-open that main screen as well.
  </p>
  <div style="text-align: center">
    <h3 style="text-align: center">
      spinnakerPixelFormat.adl</h3>
    <img alt="spinnakerPixelFormat.png" src="spinnakerPixelFormat.png" /></div>
</body>
</html>
